{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e3b4305-a2ea-4122-8477-dcabab51e760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b588c8ad-4625-49cc-8663-c162a795d12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../artifacts/sentiment_analysis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfa58aa2-730d-4281-834b-26f64c618344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>#fingerprint #Pregnancy Test https://goo.gl/h1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Finally a transparant silicon case ^^ Thanks t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>We love this! Would you go? #talk #makememorie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>I'm wired I know I'm George I was made that wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>What amazing service! Apple won't even talk to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0  #fingerprint #Pregnancy Test https://goo.gl/h1...\n",
       "1   2      0  Finally a transparant silicon case ^^ Thanks t...\n",
       "2   3      0  We love this! Would you go? #talk #makememorie...\n",
       "3   4      0  I'm wired I know I'm George I was made that wa...\n",
       "4   5      1  What amazing service! Apple won't even talk to..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee22b2ea-9acd-42b6-8ae6-a5423e324a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7920, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2690a775-2584-48f8-80d7-4cf136ada169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bc6475-958b-4aa4-89f6-9c25c3dd4007",
   "metadata": {},
   "source": [
    "## text preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b20554-e7fc-42f7-8038-cdbe507975d8",
   "metadata": {},
   "source": [
    "convert uppercase to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10b5b41b-e921-475b-b087-4bac6dabe4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tweet'] = data['tweet'].apply(lambda x: \" \".join(x.lower () for x in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14297d33-6756-46e7-8236-444c33fa3d67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>#fingerprint #pregnancy test https://goo.gl/h1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>finally a transparant silicon case ^^ thanks t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>we love this! would you go? #talk #makememorie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>i'm wired i know i'm george i was made that wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>what amazing service! apple won't even talk to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0  #fingerprint #pregnancy test https://goo.gl/h1...\n",
       "1   2      0  finally a transparant silicon case ^^ thanks t...\n",
       "2   3      0  we love this! would you go? #talk #makememorie...\n",
       "3   4      0  i'm wired i know i'm george i was made that wa...\n",
       "4   5      1  what amazing service! apple won't even talk to..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891ddedd-deaa-4a5a-a937-3b892b521514",
   "metadata": {},
   "source": [
    "remove links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50647b4b-de66-4b20-8422-57764b8ae431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_links(text):\n",
    "    # Define a regular expression pattern to match URLs\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    \n",
    "    # Use sub() method to replace URLs with an empty string\n",
    "    text_without_links = url_pattern.sub('', text)\n",
    "    \n",
    "    return text_without_links\n",
    "\n",
    "data[\"tweet\"] = data[\"tweet\"].apply(remove_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "436d0a42-ee37-4b6a-90d1-1afe3446d412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>#fingerprint #pregnancy test  #android #apps #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>finally a transparant silicon case ^^ thanks t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>we love this! would you go? #talk #makememorie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>i'm wired i know i'm george i was made that wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>what amazing service! apple won't even talk to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0  #fingerprint #pregnancy test  #android #apps #...\n",
       "1   2      0  finally a transparant silicon case ^^ thanks t...\n",
       "2   3      0  we love this! would you go? #talk #makememorie...\n",
       "3   4      0  i'm wired i know i'm george i was made that wa...\n",
       "4   5      1  what amazing service! apple won't even talk to..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39ce254-31bb-465f-b1f6-0e08de65046c",
   "metadata": {},
   "source": [
    "remover punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4988afd6-1e0b-41be-b660-1abda05f4772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    text_without_punct = text.translate(translator)\n",
    "    return text_without_punct\n",
    "\n",
    "data[\"tweet\"] = data[\"tweet\"].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b8d1016-b0fb-49f7-9157-e6da4bdc3a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>fingerprint pregnancy test  android apps beaut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>finally a transparant silicon case  thanks to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>we love this would you go talk makememories un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>im wired i know im george i was made that way ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>what amazing service apple wont even talk to m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0  fingerprint pregnancy test  android apps beaut...\n",
       "1   2      0  finally a transparant silicon case  thanks to ...\n",
       "2   3      0  we love this would you go talk makememories un...\n",
       "3   4      0  im wired i know im george i was made that way ...\n",
       "4   5      1  what amazing service apple wont even talk to m..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "016f1545-a7c1-4980-b4f0-fdd7d8762bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    fingerprint pregnancy test  android apps beaut...\n",
       "1    finally a transparant silicon case  thanks to ...\n",
       "2    we love this would you go talk makememories un...\n",
       "3    im wired i know im george i was made that way ...\n",
       "4    what amazing service apple wont even talk to m...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"tweet\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0838b622-e37c-4c85-a701-78403d4be273",
   "metadata": {},
   "source": [
    "remove numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6ec9012-7ff8-4843-803a-f61e0e0fbf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_numbers(text):\n",
    "    # Define a regular expression pattern to match numbers\n",
    "    number_pattern = re.compile(r'\\d+')\n",
    "    \n",
    "    # Use sub() method to replace numbers with an empty string\n",
    "    text_without_numbers = number_pattern.sub('', text)\n",
    "    \n",
    "    return text_without_numbers\n",
    "\n",
    "data[\"tweet\"] = data[\"tweet\"].apply(remove_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "491dbeac-d002-4462-b72d-ecec450b6627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7910    perfect match instagood applewatch red instagr...\n",
       "7911    i am completely in love with the new iphone em...\n",
       "7912    tune in turn on drop out  gtd in one app  mobi...\n",
       "7913    ok so my galaxy crashed after one day now i ha...\n",
       "7914    gain followers rt this must follow me i follow...\n",
       "7915    live out loud lol liveoutloud selfie smile son...\n",
       "7916    we would like to wish you an amazing day make ...\n",
       "7917    helping my lovely  year old neighbor with her ...\n",
       "7918    finally got my smart pocket wifi stay connecte...\n",
       "7919    apple barcelona apple store bcn barcelona trav...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"tweet\"].tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ed88df-119b-4710-b9e3-7c89113cb622",
   "metadata": {},
   "source": [
    "remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9d066f3-87eb-40a3-ab90-09a399b1c15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10d45179-8874-42a1-ad17-a9db467c1437",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../static/model/corpora/stopwords/english', 'r') as file:\n",
    "    sw = file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5fbcc4f-ee17-4086-88e1-04825b9dcf33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b3e89e8-9c45-4e88-9c07-c0b74ff92aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    # Tokenize the text into words\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    filtered_words = [word for word in words if word.lower() not in stopwords.words('english')]\n",
    "    \n",
    "    # Join the filtered words back into a sentence\n",
    "    text_without_stopwords = ' '.join(filtered_words)\n",
    "    \n",
    "    return text_without_stopwords\n",
    "\n",
    "data[\"tweet\"] = data[\"tweet\"].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "457d3b1f-41ff-4e74-ae17-7b233b641a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>fingerprint pregnancy test android apps beauti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>finally transparant silicon case thanks uncle ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>love would go talk makememories unplug relax i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>im wired know im george made way iphone cute d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>amazing service apple wont even talk question ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0  fingerprint pregnancy test android apps beauti...\n",
       "1   2      0  finally transparant silicon case thanks uncle ...\n",
       "2   3      0  love would go talk makememories unplug relax i...\n",
       "3   4      0  im wired know im george made way iphone cute d...\n",
       "4   5      1  amazing service apple wont even talk question ..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2179b98-ddc3-467c-aaaf-ee0fa4fee8cd",
   "metadata": {},
   "source": [
    "stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b220232-762f-4e46-8116-22e081a13359",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "def apply_stemming(text):\n",
    "    # Tokenize the text into words\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Initialize the Porter Stemmer\n",
    "    porter_stemmer = PorterStemmer()\n",
    "    \n",
    "    # Apply stemming to each word\n",
    "    stemmed_words = [porter_stemmer.stem(word) for word in words]\n",
    "    \n",
    "    # Join the stemmed words back into a sentence\n",
    "    text_after_stemming = ' '.join(stemmed_words)\n",
    "    \n",
    "    return text_after_stemming\n",
    "\n",
    "data[\"tweet\"] = data[\"tweet\"].apply(apply_stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0966255-c11a-4f6f-8a3e-fd56414ffd49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>fingerprint pregnanc test android app beauti c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>final transpar silicon case thank uncl yay son...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>love would go talk makememori unplug relax iph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>im wire know im georg made way iphon cute dave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>amaz servic appl wont even talk question unles...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0  fingerprint pregnanc test android app beauti c...\n",
       "1   2      0  final transpar silicon case thank uncl yay son...\n",
       "2   3      0  love would go talk makememori unplug relax iph...\n",
       "3   4      0  im wire know im georg made way iphon cute dave...\n",
       "4   5      1  amaz servic appl wont even talk question unles..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60e73a00-6279-478a-aff1-e59e784e12ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>fingerprint pregnanc test android app beauti c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>final transpar silicon case thank uncl yay son...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>love would go talk makememori unplug relax iph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>im wire know im georg made way iphon cute dave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>amaz servic appl wont even talk question unles...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7915</th>\n",
       "      <td>7916</td>\n",
       "      <td>0</td>\n",
       "      <td>live loud lol liveoutloud selfi smile soni mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7916</th>\n",
       "      <td>7917</td>\n",
       "      <td>0</td>\n",
       "      <td>would like wish amaz day make everi minut coun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7917</th>\n",
       "      <td>7918</td>\n",
       "      <td>0</td>\n",
       "      <td>help love year old neighbor ipad morn made rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7918</th>\n",
       "      <td>7919</td>\n",
       "      <td>0</td>\n",
       "      <td>final got smart pocket wifi stay connect anyti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7919</th>\n",
       "      <td>7920</td>\n",
       "      <td>0</td>\n",
       "      <td>appl barcelona appl store bcn barcelona travel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7920 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  label                                              tweet\n",
       "0        1      0  fingerprint pregnanc test android app beauti c...\n",
       "1        2      0  final transpar silicon case thank uncl yay son...\n",
       "2        3      0  love would go talk makememori unplug relax iph...\n",
       "3        4      0  im wire know im georg made way iphon cute dave...\n",
       "4        5      1  amaz servic appl wont even talk question unles...\n",
       "...    ...    ...                                                ...\n",
       "7915  7916      0  live loud lol liveoutloud selfi smile soni mus...\n",
       "7916  7917      0  would like wish amaz day make everi minut coun...\n",
       "7917  7918      0  help love year old neighbor ipad morn made rea...\n",
       "7918  7919      0  final got smart pocket wifi stay connect anyti...\n",
       "7919  7920      0  appl barcelona appl store bcn barcelona travel...\n",
       "\n",
       "[7920 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6316842-2f88-4b77-bd1e-1639f29dbe2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>fingerprint pregnanc test android app beauti c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>final transpar silicon case thank uncl yay son...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>love would go talk makememori unplug relax iph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>im wire know im georg made way iphon cute dave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>amaz servic appl wont even talk question unles...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7915</th>\n",
       "      <td>7916</td>\n",
       "      <td>0</td>\n",
       "      <td>live loud lol liveoutloud selfi smile soni mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7916</th>\n",
       "      <td>7917</td>\n",
       "      <td>0</td>\n",
       "      <td>would like wish amaz day make everi minut coun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7917</th>\n",
       "      <td>7918</td>\n",
       "      <td>0</td>\n",
       "      <td>help love year old neighbor ipad morn made rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7918</th>\n",
       "      <td>7919</td>\n",
       "      <td>0</td>\n",
       "      <td>final got smart pocket wifi stay connect anyti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7919</th>\n",
       "      <td>7920</td>\n",
       "      <td>0</td>\n",
       "      <td>appl barcelona appl store bcn barcelona travel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7920 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  label                                              tweet\n",
       "0        1      0  fingerprint pregnanc test android app beauti c...\n",
       "1        2      0  final transpar silicon case thank uncl yay son...\n",
       "2        3      0  love would go talk makememori unplug relax iph...\n",
       "3        4      0  im wire know im georg made way iphon cute dave...\n",
       "4        5      1  amaz servic appl wont even talk question unles...\n",
       "...    ...    ...                                                ...\n",
       "7915  7916      0  live loud lol liveoutloud selfi smile soni mus...\n",
       "7916  7917      0  would like wish amaz day make everi minut coun...\n",
       "7917  7918      0  help love year old neighbor ipad morn made rea...\n",
       "7918  7919      0  final got smart pocket wifi stay connect anyti...\n",
       "7919  7920      0  appl barcelona appl store bcn barcelona travel...\n",
       "\n",
       "[7920 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2573e3-59f1-4dae-bac5-719b58f722d8",
   "metadata": {},
   "source": [
    "## building vacabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25b8e92f-d5f6-4d94-8dba-c77924f2d4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "vocab = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6148124-488a-44b3-96ba-c17b716d6509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ca901ce-3fcc-426d-960e-63141ee7ecf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       fingerprint pregnanc test android app beauti c...\n",
       "1       final transpar silicon case thank uncl yay son...\n",
       "2       love would go talk makememori unplug relax iph...\n",
       "3       im wire know im georg made way iphon cute dave...\n",
       "4       amaz servic appl wont even talk question unles...\n",
       "                              ...                        \n",
       "7915    live loud lol liveoutloud selfi smile soni mus...\n",
       "7916    would like wish amaz day make everi minut coun...\n",
       "7917    help love year old neighbor ipad morn made rea...\n",
       "7918    final got smart pocket wifi stay connect anyti...\n",
       "7919    appl barcelona appl store bcn barcelona travel...\n",
       "Name: tweet, Length: 7920, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "422c78ac-a54b-489d-a846-ec097a7e2de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in data['tweet']:\n",
    "    vocab.update(sentence.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e3552d8b-5869-4741-afd6-2f011eaf12f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15809"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e1ce578f-0de4-4657-a842-8f31e01660af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7920, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "de8c45d6-3b8d-4bd8-84a2-aa4465086715",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [key for key in vocab if vocab[key] > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6c59708e-306e-4082-ac61-409cbc4a5ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test',\n",
       " 'android',\n",
       " 'app',\n",
       " 'beauti',\n",
       " 'cute',\n",
       " 'health',\n",
       " 'iger',\n",
       " 'iphoneonli',\n",
       " 'iphonesia',\n",
       " 'iphon',\n",
       " 'final',\n",
       " 'case',\n",
       " 'thank',\n",
       " 'yay',\n",
       " 'soni',\n",
       " 'xperia',\n",
       " 'love',\n",
       " 'would',\n",
       " 'go',\n",
       " 'talk',\n",
       " 'relax',\n",
       " 'smartphon',\n",
       " 'wifi',\n",
       " 'connect',\n",
       " 'im',\n",
       " 'know',\n",
       " 'made',\n",
       " 'way',\n",
       " 'home',\n",
       " 'amaz',\n",
       " 'servic',\n",
       " 'appl',\n",
       " 'wont',\n",
       " 'even',\n",
       " 'question',\n",
       " 'pay',\n",
       " 'stupid',\n",
       " 'support',\n",
       " 'softwar',\n",
       " 'updat',\n",
       " 'fuck',\n",
       " 'phone',\n",
       " 'big',\n",
       " 'time',\n",
       " 'happi',\n",
       " 'us',\n",
       " 'instap',\n",
       " 'instadaili',\n",
       " 'xperiaz',\n",
       " 'new',\n",
       " 'type',\n",
       " 'c',\n",
       " 'charger',\n",
       " 'cabl',\n",
       " 'uk',\n",
       " '…',\n",
       " 'amazon',\n",
       " 'year',\n",
       " 'newyear',\n",
       " 'start',\n",
       " 'technolog',\n",
       " 'samsunggalaxi',\n",
       " 'iphonex',\n",
       " 'shop',\n",
       " 'listen',\n",
       " 'music',\n",
       " 'likeforlik',\n",
       " 'photo',\n",
       " 'fun',\n",
       " 'selfi',\n",
       " 'water',\n",
       " 'camera',\n",
       " 'picoftheday',\n",
       " 'sun',\n",
       " 'instagood',\n",
       " 'boy',\n",
       " 'outdoor',\n",
       " 'hey',\n",
       " 'make',\n",
       " 'ipod',\n",
       " 'dont',\n",
       " 'color',\n",
       " 'inch',\n",
       " 'crash',\n",
       " 'everi',\n",
       " 'need',\n",
       " 'realli',\n",
       " 'drop',\n",
       " 'ball',\n",
       " 'design',\n",
       " 'give',\n",
       " 'anoth',\n",
       " 'crazi',\n",
       " 'purchas',\n",
       " 'lol',\n",
       " 'work',\n",
       " 'hard',\n",
       " 'play',\n",
       " 'ipad',\n",
       " 'batteri',\n",
       " 'charg',\n",
       " 'dead',\n",
       " 'saturday',\n",
       " 'summer',\n",
       " 'like',\n",
       " 'share',\n",
       " 'want',\n",
       " 'instagram',\n",
       " 'photooftheday',\n",
       " 'tweegram',\n",
       " 'reason',\n",
       " 'one',\n",
       " 'suck',\n",
       " 'truth',\n",
       " 'agre',\n",
       " 'fact',\n",
       " 'store',\n",
       " 'screen',\n",
       " 'monday',\n",
       " 'ur',\n",
       " 'art',\n",
       " 'easter',\n",
       " 'dear',\n",
       " 'friend',\n",
       " 'face',\n",
       " 'email',\n",
       " 'seem',\n",
       " 'pie',\n",
       " 'wife',\n",
       " 'ive',\n",
       " 'day',\n",
       " 'button',\n",
       " 'back',\n",
       " 'broke',\n",
       " 'hit',\n",
       " 'goe',\n",
       " 'complet',\n",
       " 'black',\n",
       " 'keep',\n",
       " 'get',\n",
       " 'text',\n",
       " 'cant',\n",
       " 'check',\n",
       " 'wallpap',\n",
       " 'wall',\n",
       " 'galaxi',\n",
       " 'samsung',\n",
       " 'patent',\n",
       " 'million',\n",
       " 'parti',\n",
       " 'mess',\n",
       " 'havent',\n",
       " 'done',\n",
       " 'noth',\n",
       " 'touch',\n",
       " 'lose',\n",
       " 'pic',\n",
       " 'kill',\n",
       " 'someon',\n",
       " 'hateappl',\n",
       " 'flower',\n",
       " 'green',\n",
       " 'must',\n",
       " 'watch',\n",
       " 'youtub',\n",
       " 'subscrib',\n",
       " 'daili',\n",
       " 'vlog',\n",
       " 'twitch',\n",
       " 'game',\n",
       " 'ps',\n",
       " 'xbox',\n",
       " 'io',\n",
       " 'live',\n",
       " 'laugh',\n",
       " 'life',\n",
       " 'food',\n",
       " 'instago',\n",
       " 'instahub',\n",
       " 'instagram…',\n",
       " 'friendship',\n",
       " 'dog',\n",
       " 'famili',\n",
       " 'goal',\n",
       " 'bestfriend',\n",
       " 'america',\n",
       " 'taken',\n",
       " 'sunset',\n",
       " 'sky',\n",
       " 'sister',\n",
       " 'bought',\n",
       " 'earli',\n",
       " 'bday',\n",
       " 'gift',\n",
       " 'receiv',\n",
       " 'note',\n",
       " 'mani',\n",
       " 'market',\n",
       " 'delet',\n",
       " 'song',\n",
       " 'itun',\n",
       " 'freak',\n",
       " 'window',\n",
       " 'advanc',\n",
       " 'custom',\n",
       " 'stand',\n",
       " 'bad',\n",
       " 'cheap',\n",
       " 'tech',\n",
       " 'bull',\n",
       " 'smile',\n",
       " '’',\n",
       " 'creat',\n",
       " 'let',\n",
       " 'sunday',\n",
       " 'alway',\n",
       " 'eye',\n",
       " 'ootd',\n",
       " 'fashion',\n",
       " 'blackandwhit',\n",
       " 'film',\n",
       " 'set',\n",
       " 'video',\n",
       " 'produc',\n",
       " 'follow',\n",
       " 'movi',\n",
       " 'act',\n",
       " 'pink',\n",
       " 'sweet',\n",
       " 'sexi',\n",
       " 'ladi',\n",
       " 'week',\n",
       " 'end',\n",
       " 'iphoneplu',\n",
       " 'moment',\n",
       " 'see',\n",
       " 'differ',\n",
       " 'photographi',\n",
       " 'natur',\n",
       " 'landscap',\n",
       " 'view',\n",
       " 'tree',\n",
       " 'travel',\n",
       " 'googl',\n",
       " 'cut',\n",
       " 'program',\n",
       " 'look',\n",
       " 'got',\n",
       " 'christma',\n",
       " 'girl',\n",
       " 'instacool',\n",
       " 'free',\n",
       " 'appstor',\n",
       " 'joy',\n",
       " 'peac',\n",
       " 'reflect',\n",
       " 'rememb',\n",
       " 'cloud',\n",
       " 'gr',\n",
       " 'iphone…',\n",
       " 'babi',\n",
       " 'pet',\n",
       " 'news',\n",
       " 'fail',\n",
       " 'funni',\n",
       " 'hate',\n",
       " 'tablet',\n",
       " 'person',\n",
       " 'use',\n",
       " 'fan',\n",
       " 'think',\n",
       " 'product',\n",
       " 'friday',\n",
       " 'call',\n",
       " '‘',\n",
       " 'blackfriday',\n",
       " 'holiday',\n",
       " 'newyork',\n",
       " 'busi',\n",
       " 'money',\n",
       " 'birthday',\n",
       " 'tv',\n",
       " 'comput',\n",
       " 'school',\n",
       " 'serious',\n",
       " 'els',\n",
       " '“',\n",
       " '”',\n",
       " 'month',\n",
       " 'good',\n",
       " 'job',\n",
       " 'actual',\n",
       " '£',\n",
       " 'replac',\n",
       " 'that',\n",
       " 'still',\n",
       " 'rt',\n",
       " 'droid',\n",
       " 'cool',\n",
       " 'pictur',\n",
       " 'l',\n",
       " 'run',\n",
       " 'beach',\n",
       " 'sport',\n",
       " 'bit',\n",
       " 'hashtag',\n",
       " 'yet',\n",
       " 'arriv',\n",
       " 'gain',\n",
       " 'everyon',\n",
       " 'sougofollow',\n",
       " 'ff',\n",
       " 'iphoneographi',\n",
       " 'iphonephotographi',\n",
       " 'mobil',\n",
       " 'bright',\n",
       " 'user',\n",
       " 'date',\n",
       " 'less',\n",
       " 'random',\n",
       " 'instamood',\n",
       " 'wine',\n",
       " 'creativ',\n",
       " 'hot',\n",
       " 'icon',\n",
       " 'origin',\n",
       " 'pop',\n",
       " 'red',\n",
       " 'rock',\n",
       " 'soul',\n",
       " 'singer',\n",
       " 'univers',\n",
       " 'wed',\n",
       " 'thought',\n",
       " 'id',\n",
       " 'lost',\n",
       " 'ipadmini',\n",
       " 'feel',\n",
       " 'broken',\n",
       " 'light',\n",
       " 'pleas',\n",
       " 'indonesia',\n",
       " 'gold',\n",
       " 'potd',\n",
       " 'reset',\n",
       " 'sorri',\n",
       " 'white',\n",
       " 'tea',\n",
       " 'chill',\n",
       " 'cover',\n",
       " 'g',\n",
       " 'came',\n",
       " 'magic',\n",
       " 'come',\n",
       " 'followsunday',\n",
       " 'followback',\n",
       " 'teamfollowback',\n",
       " 'retweet',\n",
       " 'ya',\n",
       " 'thing',\n",
       " 'alreadi',\n",
       " 'problem',\n",
       " 'issu',\n",
       " 'abl',\n",
       " 'sonya',\n",
       " 'shoot',\n",
       " 'put',\n",
       " 'price',\n",
       " 'devic',\n",
       " 'win',\n",
       " 'box',\n",
       " 'memori',\n",
       " 'brother',\n",
       " '–',\n",
       " 'oh',\n",
       " 'lip',\n",
       " 'enjoy',\n",
       " 'playstat',\n",
       " 'gamer',\n",
       " 'someth',\n",
       " 'wrong',\n",
       " 'right',\n",
       " 'today',\n",
       " 'earphon',\n",
       " 'lifestyl',\n",
       " 'fuckyou',\n",
       " 'never',\n",
       " 'bug',\n",
       " 'littl',\n",
       " 'qualiti',\n",
       " 'girlfriend',\n",
       " 'card',\n",
       " 'z',\n",
       " 'present',\n",
       " 'mom',\n",
       " 'macbookpro',\n",
       " 'macbook',\n",
       " 'quot',\n",
       " 'word',\n",
       " 'tweetgram',\n",
       " 'great',\n",
       " 'repair',\n",
       " 'hour',\n",
       " 'everyth',\n",
       " 'mode',\n",
       " 'usa',\n",
       " 'compani',\n",
       " 'model',\n",
       " 'cd',\n",
       " 'featur',\n",
       " 'didnt',\n",
       " 'coffe',\n",
       " 'effect',\n",
       " 'spring',\n",
       " 'galaxynot',\n",
       " 'special',\n",
       " 'valentin',\n",
       " 'nowplay',\n",
       " 'daughter',\n",
       " 'poem',\n",
       " 'car',\n",
       " 'sign',\n",
       " 'lunch',\n",
       " 'park',\n",
       " 'banana',\n",
       " 'autumn',\n",
       " 'spend',\n",
       " 'much',\n",
       " 'book',\n",
       " 'say',\n",
       " 'u',\n",
       " 'took',\n",
       " 'download',\n",
       " 'ad',\n",
       " 'twitter',\n",
       " 'educ',\n",
       " 'n',\n",
       " 'miss',\n",
       " 'last',\n",
       " 'min',\n",
       " 'tmobil',\n",
       " 'rid',\n",
       " 'absolut',\n",
       " 'annoy',\n",
       " 'level',\n",
       " 'buy',\n",
       " 'full',\n",
       " 'version',\n",
       " 'import',\n",
       " 'mood',\n",
       " 'blog',\n",
       " 'style',\n",
       " 'bestoftheday',\n",
       " 'pretti',\n",
       " 'babe',\n",
       " 'send',\n",
       " 'turn',\n",
       " 'imessag',\n",
       " 'sleep',\n",
       " 'popular',\n",
       " 'tweet',\n",
       " 'shotoniphon',\n",
       " 'photograph',\n",
       " 'sync',\n",
       " 'second',\n",
       " 'fml',\n",
       " 'candi',\n",
       " 'nice',\n",
       " 'wait',\n",
       " 'hand',\n",
       " 'gb',\n",
       " 'first',\n",
       " 'bar',\n",
       " 'key',\n",
       " 'long',\n",
       " 'cold',\n",
       " 'boot',\n",
       " 'siri',\n",
       " 'doesnt',\n",
       " 'liter',\n",
       " 'cri',\n",
       " 'contact',\n",
       " 'wonder',\n",
       " 'avail',\n",
       " 'b',\n",
       " 'laptop',\n",
       " 'vaio',\n",
       " 'blackberri',\n",
       " 'best',\n",
       " 'fruit',\n",
       " 'fall',\n",
       " 'soon',\n",
       " 'yum',\n",
       " 'mac',\n",
       " 'display',\n",
       " 'told',\n",
       " 'stop',\n",
       " 'p',\n",
       " 'three',\n",
       " 'ship',\n",
       " 'gear',\n",
       " 'well',\n",
       " 'past',\n",
       " 'singl',\n",
       " 'capetownsup',\n",
       " 'sup',\n",
       " 'surf',\n",
       " 'capetown',\n",
       " 'pro',\n",
       " 'half',\n",
       " 'stuff',\n",
       " 'excit',\n",
       " 'open',\n",
       " 'mine',\n",
       " 'piss',\n",
       " 'offici',\n",
       " 'keyboard',\n",
       " 'okay',\n",
       " 'though',\n",
       " 'enough',\n",
       " 'simpl',\n",
       " 'th',\n",
       " 'refus',\n",
       " 'night',\n",
       " 'father',\n",
       " 'son',\n",
       " 'instagood…',\n",
       " 'jj',\n",
       " 'makeup',\n",
       " 'valentinesday',\n",
       " 'februari',\n",
       " 'portrait',\n",
       " 'shot',\n",
       " 'sonyalpha',\n",
       " 'mm',\n",
       " 'password',\n",
       " 'zoom',\n",
       " 'stevejob',\n",
       " 'yall',\n",
       " 'addict',\n",
       " 'prophet',\n",
       " 'husband',\n",
       " 'kindl',\n",
       " 'a…',\n",
       " 'upgrad',\n",
       " 'help',\n",
       " 'children',\n",
       " 'there',\n",
       " 'least',\n",
       " 'tab',\n",
       " 'real',\n",
       " 'visit',\n",
       " 'hi',\n",
       " 'world',\n",
       " 'old',\n",
       " 'followm',\n",
       " 'likelik',\n",
       " 'samsung…',\n",
       " 'swag',\n",
       " 'cat',\n",
       " 'edit',\n",
       " 'sick',\n",
       " 'paint',\n",
       " 'bullshit',\n",
       " 'may',\n",
       " 'perfect',\n",
       " 'instaphoto',\n",
       " 'welcom',\n",
       " 'draw',\n",
       " 'os',\n",
       " 'throw',\n",
       " 'fast',\n",
       " 'w',\n",
       " 'take',\n",
       " 'two',\n",
       " 'next',\n",
       " 'offer',\n",
       " 'middl',\n",
       " 'access',\n",
       " 'account',\n",
       " 'find',\n",
       " 'citi',\n",
       " 'stori',\n",
       " 'destini',\n",
       " 'awesom',\n",
       " 'accessori',\n",
       " 'info',\n",
       " 'goodnight',\n",
       " 'dream',\n",
       " 'hope',\n",
       " 'uae',\n",
       " 'lucki',\n",
       " 'deal',\n",
       " 'passion',\n",
       " 'read',\n",
       " 'edm',\n",
       " 'whole',\n",
       " 'playlist',\n",
       " 'god',\n",
       " 'nx',\n",
       " 'cuti',\n",
       " 'high',\n",
       " 'usb',\n",
       " 'geek',\n",
       " 'bot',\n",
       " 'gadget',\n",
       " 'power',\n",
       " 'pc',\n",
       " 'sprint',\n",
       " 'pick',\n",
       " 'wish',\n",
       " 'minut',\n",
       " 'count',\n",
       " 'tl',\n",
       " 'drive',\n",
       " 'nyc',\n",
       " 'gay',\n",
       " 'readi',\n",
       " 'cellphon',\n",
       " 'space',\n",
       " 'ny',\n",
       " 'tattoo',\n",
       " 'total',\n",
       " 'ye',\n",
       " 'via',\n",
       " 'air',\n",
       " 'instal',\n",
       " 'fit',\n",
       " 'plu',\n",
       " 'sim',\n",
       " 'florida',\n",
       " 'sale',\n",
       " 'nokia',\n",
       " 'motorola',\n",
       " 'lg',\n",
       " 'without',\n",
       " 'hold',\n",
       " 'speed',\n",
       " 'unitedst',\n",
       " 'guitarplay',\n",
       " 'smart',\n",
       " 'crap',\n",
       " 'calendar',\n",
       " 'event',\n",
       " 'icloud',\n",
       " 'angri',\n",
       " 'bird',\n",
       " 'freez',\n",
       " 'ever',\n",
       " 'sinc',\n",
       " 'team',\n",
       " 'tri',\n",
       " 'convers',\n",
       " 'wouldnt',\n",
       " 'small',\n",
       " 'blue',\n",
       " '—',\n",
       " 'steemit',\n",
       " 'sonylen',\n",
       " 'len',\n",
       " 'sonyphotographi',\n",
       " 'imag',\n",
       " 'photofe',\n",
       " 'feed',\n",
       " 'yeah',\n",
       " 'gorgeou',\n",
       " 'ig',\n",
       " 'orang',\n",
       " 'haha',\n",
       " 'dress',\n",
       " 'lock',\n",
       " 'speaker',\n",
       " 'reallyr',\n",
       " 'colleg',\n",
       " 'true',\n",
       " 'chocol',\n",
       " 'shit',\n",
       " 'ador',\n",
       " 'nofilt',\n",
       " 'drink',\n",
       " 'purpl',\n",
       " 'tasti',\n",
       " 'garden',\n",
       " 'андроид',\n",
       " 'guy',\n",
       " 'bestpric',\n",
       " 'jun',\n",
       " 'unlock',\n",
       " 'caus',\n",
       " 'manag',\n",
       " 'mommi',\n",
       " 'bless',\n",
       " 'could',\n",
       " 'chines',\n",
       " 'close',\n",
       " 'system',\n",
       " 'morn',\n",
       " 'nike',\n",
       " 'goodmorn',\n",
       " 'r',\n",
       " 'imac',\n",
       " 'sell',\n",
       " 'mad',\n",
       " 'purpos',\n",
       " 'pari',\n",
       " 'answer',\n",
       " 'roll',\n",
       " 'verizon',\n",
       " 'headphon',\n",
       " 'show',\n",
       " 'sound',\n",
       " 'itali',\n",
       " 'socialmedia',\n",
       " 'learn',\n",
       " 'smoke',\n",
       " 'tomorrow',\n",
       " 'here',\n",
       " 'delici',\n",
       " 'far',\n",
       " 'away',\n",
       " 'ebay',\n",
       " 'fix',\n",
       " 'easi',\n",
       " 'silver',\n",
       " 'oneplu',\n",
       " 'provid',\n",
       " 'experi',\n",
       " 'flag',\n",
       " 'emoji',\n",
       " 'chang',\n",
       " 'al',\n",
       " 'april',\n",
       " 'man',\n",
       " 'wan',\n",
       " 'na',\n",
       " 'your',\n",
       " 'tell',\n",
       " 'kid',\n",
       " 'backup',\n",
       " 'peopl',\n",
       " 'dad',\n",
       " 'anyon',\n",
       " 'block',\n",
       " 'number',\n",
       " 'possibl',\n",
       " 'frustrat',\n",
       " 'file',\n",
       " 'bro',\n",
       " 'rhyme',\n",
       " 'thx',\n",
       " 'jailbreak',\n",
       " 'sit',\n",
       " 'restor',\n",
       " 'stock',\n",
       " 'mother',\n",
       " 'igdaili',\n",
       " 'marri',\n",
       " 'healthi',\n",
       " 'ugh',\n",
       " 'x',\n",
       " 'bc',\n",
       " 'gratitud',\n",
       " 'edg',\n",
       " 'unbox',\n",
       " 'wow',\n",
       " 'sonyphoto',\n",
       " 'top',\n",
       " 'danc',\n",
       " 'phonecas',\n",
       " 'june',\n",
       " 'sad',\n",
       " 'yellow',\n",
       " 'woman',\n",
       " 'might',\n",
       " 'india',\n",
       " 'canada',\n",
       " 'europ',\n",
       " 'super',\n",
       " 'care',\n",
       " 'map',\n",
       " 'applestor',\n",
       " 'hello',\n",
       " 'order',\n",
       " 'sent',\n",
       " 'went',\n",
       " 'wasnt',\n",
       " 'insta',\n",
       " 'newphon',\n",
       " 'fish',\n",
       " 'london',\n",
       " 'vsco',\n",
       " 'track',\n",
       " 'catch',\n",
       " 'finger',\n",
       " 'anymor',\n",
       " 'captur',\n",
       " 'futur',\n",
       " 'cell',\n",
       " 'instalik',\n",
       " 'sony…',\n",
       " 'march',\n",
       " 'proud',\n",
       " 'hateiphon',\n",
       " 'sticker',\n",
       " 'vscocam',\n",
       " 'bring',\n",
       " 'better',\n",
       " 'kiss',\n",
       " 'heart',\n",
       " 'fresh',\n",
       " 'librari',\n",
       " 'inspir',\n",
       " 'inlov',\n",
       " 'luxuri',\n",
       " 'exquisit',\n",
       " 'squishi',\n",
       " 'charm',\n",
       " 'strap',\n",
       " 'toy',\n",
       " 'decor',\n",
       " 'cake',\n",
       " 'theyr',\n",
       " 'lte',\n",
       " 'facebook',\n",
       " 'wipe',\n",
       " 'human',\n",
       " 'bff',\n",
       " 'instalov',\n",
       " 'storag',\n",
       " 'wake',\n",
       " 'shitti',\n",
       " 'wast',\n",
       " 'switch',\n",
       " 'blond',\n",
       " 'load',\n",
       " 'sue',\n",
       " 'teamandroid',\n",
       " 'da',\n",
       " 'ly',\n",
       " 'lion',\n",
       " 'steve',\n",
       " 'also',\n",
       " 'ill',\n",
       " 'osx',\n",
       " 'photoshoot',\n",
       " 'coupl',\n",
       " 'favorit',\n",
       " 'forc',\n",
       " 'newtoy',\n",
       " 'nascar',\n",
       " 'tire',\n",
       " 'appar',\n",
       " 'ago',\n",
       " 'zeeland',\n",
       " 'appletv',\n",
       " 'ask',\n",
       " 'said',\n",
       " 'meet',\n",
       " 'electron',\n",
       " 'gener',\n",
       " 'link',\n",
       " 'code',\n",
       " 'tshirt',\n",
       " 'tbt',\n",
       " 'beat',\n",
       " 'screw',\n",
       " 'videogam',\n",
       " 'motiv',\n",
       " 'sunni',\n",
       " 'nikon',\n",
       " 'useless',\n",
       " 'boyfriend',\n",
       " 'weekend',\n",
       " 'cook',\n",
       " 'japan',\n",
       " 'starbuck',\n",
       " 'almost',\n",
       " 'cousin',\n",
       " 'tag',\n",
       " 'applesuck',\n",
       " 'everyday',\n",
       " 'bye',\n",
       " 'search',\n",
       " 'dinner',\n",
       " 'discount',\n",
       " 'cheer',\n",
       " 'bluetooth',\n",
       " 'wireless',\n",
       " 'data',\n",
       " 'spent',\n",
       " 'puppi',\n",
       " 'vacat',\n",
       " 'anim',\n",
       " 'notebook',\n",
       " 'redbubbl',\n",
       " 'iphonecas',\n",
       " 'king',\n",
       " 'yo',\n",
       " 'left',\n",
       " 'mean',\n",
       " 'what',\n",
       " 'yesterday',\n",
       " 'mayb',\n",
       " 'trump',\n",
       " 'california',\n",
       " 'repost',\n",
       " 'samsungmobil',\n",
       " 'gone',\n",
       " 'social',\n",
       " 'break',\n",
       " 'trip',\n",
       " 'slow',\n",
       " 'rain',\n",
       " 'wtf',\n",
       " 'anyth',\n",
       " 'cuz',\n",
       " 'hd',\n",
       " 'microsoft',\n",
       " 'applewatch',\n",
       " 'duo',\n",
       " 'dj',\n",
       " 'save',\n",
       " 'mr',\n",
       " 'releas',\n",
       " 'gon',\n",
       " 'entir',\n",
       " 'part',\n",
       " 'die',\n",
       " 'k',\n",
       " 'tip',\n",
       " 'ta',\n",
       " 'eat',\n",
       " 'walk',\n",
       " 'side',\n",
       " 'explor',\n",
       " 'hous',\n",
       " 'room',\n",
       " 'rs',\n",
       " 'piano',\n",
       " 'v',\n",
       " 'thankyou',\n",
       " 'happen',\n",
       " 'page',\n",
       " 'surpris',\n",
       " 'deliveri',\n",
       " 'messag',\n",
       " 'vocat',\n",
       " 'thailand',\n",
       " 'khaoko',\n",
       " 'ilc',\n",
       " 'snapspeed…',\n",
       " 'merri',\n",
       " 'htc',\n",
       " 'q',\n",
       " 'onlin',\n",
       " 'psn',\n",
       " 'flash',\n",
       " '•',\n",
       " 'treat',\n",
       " 'tagsforlik',\n",
       " 'cost',\n",
       " 'crack',\n",
       " 'collect',\n",
       " 'stuck',\n",
       " 'planet',\n",
       " 'men',\n",
       " 'followfollow',\n",
       " 'blow',\n",
       " 'latest',\n",
       " 'consol',\n",
       " 'blogger',\n",
       " 'protect',\n",
       " 'skin',\n",
       " 'choos',\n",
       " 'uniqu',\n",
       " 'piec',\n",
       " 'lot',\n",
       " 'remov',\n",
       " 'secur',\n",
       " 'princess',\n",
       " 'mind',\n",
       " 'becom',\n",
       " 'miami',\n",
       " 'nail',\n",
       " 'rip',\n",
       " 'figur',\n",
       " 'network',\n",
       " 'bitch',\n",
       " 'tuesday',\n",
       " 'f',\n",
       " 'idea',\n",
       " 'fb',\n",
       " 'omg',\n",
       " 'innov',\n",
       " 'player',\n",
       " 'forev',\n",
       " 'satisfi',\n",
       " 'tonight',\n",
       " 'artist',\n",
       " 'sing',\n",
       " ...]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "167c9ea8-1884-4cfd-b774-ea746ae7350f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_vocabulary(lines, filename):\n",
    "    data = '\\n'.join(lines)\n",
    "    file = open(filename, 'w', encoding=\"utf-8\")\n",
    "    file.write(data)\n",
    "    file.close()\n",
    "\n",
    "save_vocabulary(tokens, '../static/model/vocabulary.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb03dc7d-d36c-4caa-bc25-5d2eb7ebb33d",
   "metadata": {},
   "source": [
    "## devide dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c02bb858-06a3-4d45-b62a-c6a8918f2360",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['tweet']\n",
    "y = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a7b677e2-ebb3-4b61-842a-37c6ccd35b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\hi\\desktop\\sentiment_analysis_project\\env\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\users\\hi\\desktop\\sentiment_analysis_project\\env\\lib\\site-packages (from scikit-learn) (1.26.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\hi\\desktop\\sentiment_analysis_project\\env\\lib\\site-packages (from scikit-learn) (1.11.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\hi\\desktop\\sentiment_analysis_project\\env\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hi\\desktop\\sentiment_analysis_project\\env\\lib\\site-packages (from scikit-learn) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "53d51389-e4d3-4079-8e0e-4958ea17ac68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test  = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9c2da386-7acb-4c4b-9c63-cdd288c3afd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7503    great anoth iphon anoth problem flash doesnt w...\n",
       "1936    im happi mac appl bulbasaur pokemon pikachupla...\n",
       "7158    platin earn come soon top germani top world so...\n",
       "271     delici morn friday smoothi nutribullet tasti a...\n",
       "2884    rt katekc yesterday beach summer tattoo iphon ...\n",
       "                              ...                        \n",
       "2774    photo video android app unitedst cute color ig...\n",
       "908     true realtalk girltalk heartbreak true truth q...\n",
       "361         iphon sexi girl ohmann hab ich langeweil nerd\n",
       "7667        final got new phone iphon specif iphones appl\n",
       "6303    littl nemoiphoneographi iphonesia instagram ip...\n",
       "Name: tweet, Length: 6336, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "578aafef-3847-4bbc-b787-136b92611a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "331     headphon soni red headphon music igerspiura c ...\n",
       "4208    need littl sweet life vscocam squareadi instag...\n",
       "7803    gain follow rt must follow follow back follow ...\n",
       "1385    major sale htc usb power charger bulk geek tec...\n",
       "1090    simala church liteship toledoc picturex datewi...\n",
       "                              ...                        \n",
       "6244    new year case iphon plu iphon x price free shi...\n",
       "978     charg iphon comfort mobil power go iphon iphon...\n",
       "4605    whoo hoo wilmer appl ribbi kid caught stand sw...\n",
       "2946    chiefmonkey id continu hang thiev egomaniac ch...\n",
       "1613    luxuri funda woo much zeta suppli click link …...\n",
       "Name: tweet, Length: 1584, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f005ca89-aad9-4d57-9067-0b632277fe17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7503    1\n",
       "1936    0\n",
       "7158    0\n",
       "271     0\n",
       "2884    0\n",
       "       ..\n",
       "2774    0\n",
       "908     0\n",
       "361     0\n",
       "7667    0\n",
       "6303    0\n",
       "Name: label, Length: 6336, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902daf3a-e8d4-498e-acd5-ac812f42b3e3",
   "metadata": {},
   "source": [
    "### vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c03c988b-5540-4718-a459-b036a697fb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizer(ds, vocabulary):\n",
    "    vectorized_lst = []\n",
    "\n",
    "    for sentence in ds:\n",
    "        sentence_lst = np.zeros(len(vocabulary))\n",
    "\n",
    "        for i in range(len(vocabulary)):\n",
    "            if vocabulary[i] in sentence.split():\n",
    "                sentence_lst[i] = 1\n",
    "\n",
    "        vectorized_lst.append(sentence_lst)\n",
    "        \n",
    "    vectorized_lst_new = np.asarray(vectorized_lst, dtype = np.float32)\n",
    "        \n",
    "    return vectorized_lst_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3ecc4eb2-07a9-40e9-9251-1267e88669be",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_x_train = vectorizer(X_train, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "517667e4-ed70-41c8-82b2-38743a11bc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_x_test = vectorizer(X_test, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "86dc98ed-522d-4ef9-9592-b47b8d14ced4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "daf4a227-a7ac-40a1-bdbe-f84f5f2b214f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    4730\n",
       "1    1606\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79965785-bd5a-4522-a785-bea27dcc0eb5",
   "metadata": {},
   "source": [
    "### handle inbalnce dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bd455ce3-b8b2-4b5b-9bac-614c416113ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\hi\\desktop\\sentiment_analysis_project\\env\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\hi\\desktop\\sentiment_analysis_project\\env\\lib\\site-packages (from imbalanced-learn) (1.26.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\hi\\desktop\\sentiment_analysis_project\\env\\lib\\site-packages (from imbalanced-learn) (1.11.3)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\hi\\desktop\\sentiment_analysis_project\\env\\lib\\site-packages (from imbalanced-learn) (1.3.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\hi\\desktop\\sentiment_analysis_project\\env\\lib\\site-packages (from imbalanced-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hi\\desktop\\sentiment_analysis_project\\env\\lib\\site-packages (from imbalanced-learn) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "701b4191-0ab3-4cbf-9d25-9fe9f50b7bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9460, 1151) (9460,)\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE()\n",
    "vectorized_x_train_smote, y_train_smote = smote.fit_resample(vectorized_x_train, y_train)\n",
    "print(vectorized_x_train_smote.shape, y_train_smote.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "739c9095-8a5c-4503-b69c-ef49ad473205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    4730\n",
       "0    4730\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_smote.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6ad118f2-1842-44f4-bcc9-2a04e5cf4987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_x_train_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e70fd928-b1fe-448d-b25c-d57de3fa5de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "9455    1\n",
       "9456    1\n",
       "9457    1\n",
       "9458    1\n",
       "9459    1\n",
       "Name: label, Length: 9460, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "347ff6d0-2dc1-4208-9858-545eacf8d6fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "53d138e9-07be-4287-9f6a-8a43e73dddfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "331     0\n",
       "4208    0\n",
       "7803    0\n",
       "1385    0\n",
       "1090    0\n",
       "       ..\n",
       "6244    0\n",
       "978     0\n",
       "4605    0\n",
       "2946    1\n",
       "1613    0\n",
       "Name: label, Length: 1584, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57c70a4-dcb3-4492-9552-3c50a0daf543",
   "metadata": {},
   "source": [
    "## model trainng and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a228a39c-a050-4254-8d5e-cf263d3ec348",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b312986c-3fe2-4b61-a7a6-140f27952f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "def training_scores(y_act, y_pred):\n",
    "    acc = round(accuracy_score(y_act, y_pred), 3)\n",
    "    pr = round(precision_score(y_act, y_pred), 3)\n",
    "    rec = round(recall_score(y_act, y_pred), 3)\n",
    "    f1 = round(f1_score(y_act, y_pred), 3)\n",
    "    print(f'Training Scores:\\n\\tAccuracy = {acc}\\n\\tPrecision = {pr}\\n\\tRecall = {rec}\\n\\tF1-Score = {f1}')\n",
    "\n",
    "def validation_scores(y_act, y_pred):\n",
    "    acc = round(accuracy_score(y_act, y_pred), 3)\n",
    "    pr = round(precision_score(y_act, y_pred), 3)\n",
    "    rec = round(recall_score(y_act, y_pred), 3)\n",
    "    f1 = round(f1_score(y_act, y_pred), 3)\n",
    "    print(f'Training Scores:\\n\\tAccuracy = {acc}\\n\\tPrecision = {pr}\\n\\tRecall = {rec}\\n\\tF1-Score = {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf71b954-ee95-49b0-bd0b-9e7a15b7f229",
   "metadata": {},
   "source": [
    "## logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "de78fb9a-44c7-404c-acaf-668e0152ba3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Scores:\n",
      "\tAccuracy = 0.941\n",
      "\tPrecision = 0.921\n",
      "\tRecall = 0.966\n",
      "\tF1-Score = 0.943\n",
      "Training Scores:\n",
      "\tAccuracy = 0.883\n",
      "\tPrecision = 0.737\n",
      "\tRecall = 0.867\n",
      "\tF1-Score = 0.796\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(vectorized_x_train_smote, y_train_smote)\n",
    "\n",
    "y_train_pred = lr.predict(vectorized_x_train_smote)\n",
    "\n",
    "y_test_pred = lr.predict(vectorized_x_test)\n",
    "\n",
    "training_scores(y_train_smote, y_train_pred)\n",
    "\n",
    "validation_scores(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5bb2ec-c0d3-47eb-99eb-69002041239c",
   "metadata": {},
   "source": [
    "## naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "77157b95-fd45-4b7d-973f-b0eba4de52a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Scores:\n",
      "\tAccuracy = 0.907\n",
      "\tPrecision = 0.87\n",
      "\tRecall = 0.957\n",
      "\tF1-Score = 0.912\n",
      "Training Scores:\n",
      "\tAccuracy = 0.872\n",
      "\tPrecision = 0.697\n",
      "\tRecall = 0.914\n",
      "\tF1-Score = 0.791\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(vectorized_x_train_smote, y_train_smote)\n",
    "\n",
    "y_train_pred = mnb.predict(vectorized_x_train_smote)\n",
    "\n",
    "y_test_pred = mnb.predict(vectorized_x_test)\n",
    "\n",
    "training_scores(y_train_smote, y_train_pred)\n",
    "\n",
    "validation_scores(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd1dcb0-85e0-43d3-af27-6fcf583e3950",
   "metadata": {},
   "source": [
    "## decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2b88e269-ac2a-4e26-bc91-55b8c39f0009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Scores:\n",
      "\tAccuracy = 1.0\n",
      "\tPrecision = 1.0\n",
      "\tRecall = 0.999\n",
      "\tF1-Score = 1.0\n",
      "Training Scores:\n",
      "\tAccuracy = 0.838\n",
      "\tPrecision = 0.716\n",
      "\tRecall = 0.648\n",
      "\tF1-Score = 0.68\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(vectorized_x_train_smote, y_train_smote)\n",
    "\n",
    "y_train_pred = dt.predict(vectorized_x_train_smote)\n",
    "\n",
    "y_test_pred = dt.predict(vectorized_x_test)\n",
    "\n",
    "training_scores(y_train_smote, y_train_pred)\n",
    "\n",
    "validation_scores(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696ea0f4-0b01-4600-8389-7269ab09edb6",
   "metadata": {},
   "source": [
    "### randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4075e8fa-8ff8-46c5-8f0b-afd0c4a4b26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Scores:\n",
      "\tAccuracy = 1.0\n",
      "\tPrecision = 1.0\n",
      "\tRecall = 0.999\n",
      "\tF1-Score = 1.0\n",
      "Training Scores:\n",
      "\tAccuracy = 0.872\n",
      "\tPrecision = 0.779\n",
      "\tRecall = 0.724\n",
      "\tF1-Score = 0.751\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(vectorized_x_train_smote, y_train_smote)\n",
    "\n",
    "y_train_pred = rf.predict(vectorized_x_train_smote)\n",
    "\n",
    "y_test_pred = rf.predict(vectorized_x_test)\n",
    "\n",
    "training_scores(y_train_smote, y_train_pred)\n",
    "\n",
    "validation_scores(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec623e2c-c28c-436d-a1d3-7720c0a90dde",
   "metadata": {},
   "source": [
    "### support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "efc34392-1e37-4663-adbe-fff72aec7d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Scores:\n",
      "\tAccuracy = 0.979\n",
      "\tPrecision = 0.965\n",
      "\tRecall = 0.995\n",
      "\tF1-Score = 0.98\n",
      "Training Scores:\n",
      "\tAccuracy = 0.881\n",
      "\tPrecision = 0.757\n",
      "\tRecall = 0.81\n",
      "\tF1-Score = 0.783\n"
     ]
    }
   ],
   "source": [
    "svm = SVC()\n",
    "svm.fit(vectorized_x_train_smote, y_train_smote)\n",
    "\n",
    "y_train_pred = svm.predict(vectorized_x_train_smote)\n",
    "\n",
    "y_test_pred = svm.predict(vectorized_x_test)\n",
    "\n",
    "training_scores(y_train_smote, y_train_pred)\n",
    "\n",
    "validation_scores(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c7ba1b7d-1833-4801-bad2-dcb9901fced6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "with open('../static/model/model.pickle', 'wb') as file:\n",
    "    pickle.dump(lr, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec25a19-230b-4f18-bbe9-c2b95be1df64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
